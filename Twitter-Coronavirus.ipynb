import tweepy
import pandas
import numpy as np
from sklearn import datasets
import csv
from collections import Counter
import ast
import codecs
from tweepy.streaming import StreamListener
from tweepy import OAuthHandler
from tweepy import Stream
#Access tokens
access_key = '1115668915365933056-VmYM0aBjCO9s2bb3UNP6P8lRWwwWH2'
access_secret = 'wXFuHixCufmwipwXMg1S07O6IRiypBQGBHy7Jabwv1nI6'
consumer_key = 'vWNiOJRvGrCtRYA2jAU21rdrS'
consumer_secret = 'x91mm0HKk6pHWAS4xlSDVFzowgOCVOmQ57Ac0qgGYNnBKEJzqe'


# Twitter allows access to only 3240 tweets via this method

# Authorization and initialization
auth = tweepy.OAuthHandler(consumer_key, consumer_secret)
auth.set_access_token(access_key, access_secret)
api = tweepy.API(auth, wait_on_rate_limit=True)

# # Open/Create a file to append data
# csvFile = open('coronavirus.csv', 'a')
# #Use csv Writer
# csvWriter = csv.writer(csvFile)
# #e=csvFile.encode('abc.csv')
# # Define the search term and the date_since date as variables
search_words = "coronavirus"  # + " -filter:retweets"
date_since = "2019-12-01" #YYYY-MM-DD

# Collect tweets
tweets = tweepy.Cursor(api.search,
              q=search_words,
              lang="en",
              since=date_since).items(5000)

#data = pd.DataFrame(data=[tweet.text for tweet in tweets], columns= ['Tweets'])

# print(data)

# # Create our query
# query = {'q': 'dog',
#         'result_type': 'recent',
#         'count': 1000,
#         'lang': 'en',
#         }
# # Search tweets
# dict_ = {'user': [], 'date': [], 'text': [], 'favorite_count': [], 'location': []}
# for status in python_tweets.search(**query)['statuses']: #for status in python_tweets.search(**query)['statuses']:
#     dict_['user'].append(status['user']['screen_name'])
#     dict_['date'].append(status['created_at'])
#     dict_['text'].append(status['text'])
#     dict_['favorite_count'].append(status['favorite_count'])
#     dict_['location'].append(status['user']['location'])

# Running only on handle returns a dataframe 
# data = pd.DataFrame(data=[tweet.text for tweet in tweets])
# data['len']  = np.array([len(tweet.text) for tweet in tweets])
# # data['user']  = np.array([tweet.id for tweet in tweets])
# # data['location']   = np.array([tweet.location for tweet in tweets])


# print(data)

# Structure data in a pandas DataFrame for easier manipulation

# df = pd.DataFrame(dict_)
# df.sort_values(by='favorite_count', inplace=True, ascending=False)
# #df.head(5)
# print(df)
#think this is enough to get my heatmap but I really need geocoordinates
#don't really need to get the actual statuses
#try and change the location to geocoordinates? no not accurate because it will just give us the location of the city and 
#actual geocoordinates would be more specific and make for a better map

users_locs = [[tweet.user.screen_name, tweet.user.location] for tweet in tweets] #think this is enough to get my heatmap but I really need geocoordinates
users_locs



tweet_text = pandas.DataFrame(data=users_locs, 
                     columns=['user', "location"])  #this saved my life. didn't know how to turn twitter search query into dataframe
tweet_text


df = pd.DataFrame(tweet_text)
# print(df)
    

tweets = df


geolocator = Nominatim(user_agent="salemmorelli95@gmail.com")

# Go through all tweets and add locations to 'coordinates' dictionary
coordinates = {'latitude': [], 'longitude': []}
for count, user_loc in enumerate(tweets.location):
    try:
        location = geolocator.geocode(user_loc)
        
        # If coordinates are found for location
        if location:
            coordinates['latitude'].append(location.latitude)
            coordinates['longitude'].append(location.longitude)
            
    # If too many connection requests
    except:
        pass
    
# Instantiate and center a GoogleMapPlotter object to show our map
gmap = gmplot.GoogleMapPlotter(30, 0, 3, apikey="AIzaSyCOylk1VL5sh7m8B1QiyLVFVYNfytC8WF8") #I had problems here, web example missed the api attribute and so I couldn't get a proper map

# Insert points on the map passing a list of latitudes and longitudes
gmap.heatmap(coordinates['latitude'], coordinates['longitude'], radius=20)

# Save the map to html file
gmap.draw("python_heatmap.html")
